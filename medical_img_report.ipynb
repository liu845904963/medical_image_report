{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "train_df=pd.read_csv('dataset/track1_round1_train_20210222.csv',header=None)\n",
    "test_df=pd.read_csv('dataset/track1_round1_testA_20210222.csv',header=None) \n",
    "train_df.columns=['report_ID','description','label']\n",
    "test_df.columns=['report_ID','description']\n",
    "train_df.drop(['report_ID'],axis=1,inplace=True)\n",
    "test_df.drop(['report_ID'],axis=1,inplace=True)\n",
    "new_des=[i.strip('|').strip() for i in train_df['description'].values]\n",
    "new_label=[i.strip('|').strip() for i in train_df['label'].values]\n",
    "train_df['description']=new_des\n",
    "train_df['label']=new_label\n",
    "new_des=[i.strip('|').strip() for i in test_df['description'].values]\n",
    "test_df['description']=new_des\n",
    "test_df['label'] = 0\n",
    "def seed_torch(seed=1029):\n",
    "    print(\"seed:{}\".format(seed))\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bert4keras.backend import keras, search_layer, K\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.optimizers import extend_with_gradient_accumulation\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text_lists = self.data['description']\n",
    "        self.targets = self.data['label']\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def get_dumm(self,s):\n",
    "        re=[0]*17\n",
    "        if s=='':#标签为空 返回17个0\n",
    "            return re\n",
    "        else:\n",
    "            tmp=[int(i) for i in s.split(' ')]\n",
    "            for i in tmp:\n",
    "                re[i]=1\n",
    "        return re\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        text_lists = self.text_lists[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text_lists,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        targets = self.get_dumm(self.targets[index])\n",
    "        return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                'targets': torch.tensor(targets, dtype=torch.float)\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('pre/vocab.txt')\n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        \n",
    "        self.config = BertConfig.from_pretrained('pretrain6/config.json', output_hidden_states=True)\n",
    "        self.l1 = BertModel.from_pretrained('pretrain6/pytorch_model.bin', config=self.config)\n",
    "        self.bilstm1 = torch.nn.LSTM(1536, 256, 1, bidirectional=True)\n",
    "        self.l2 = torch.nn.Linear(512, 64)\n",
    "        self.a1 = torch.nn.ReLU()\n",
    "        self.l3 = torch.nn.Dropout(0.3)\n",
    "        self.l4 = torch.nn.Linear(64, 17)\n",
    "        self.l5 = torch.nn.Linear(1536,128)\n",
    "        self.l51 = torch.nn.Linear(512,128)\n",
    "        self.l6 = torch.nn.Linear(128,17)\n",
    "       ######################################\n",
    "       # 初始时间步和最终时间步的隐藏状态作为全连接层输入\n",
    "        self.w_omega = torch.nn.Parameter(torch.Tensor(\n",
    "            256 * 2, 256 * 2))\n",
    "        self.u_omega = torch.nn.Parameter(torch.Tensor(256 * 2, 1))\n",
    "        self.decoder = torch.nn.Linear(2*256, 17)\n",
    "\n",
    "        torch.nn.init.uniform_(self.w_omega, -0.1, 0.1)\n",
    "        torch.nn.init.uniform_(self.u_omega, -0.1, 0.1)\n",
    "\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        sequence_output, pooler_output, hidden_states= self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        #    bs sl hs    #bs hs\n",
    "        # [bs, sl, 768]  [bs,768]\n",
    "#=====================================================================\n",
    "#         bs = len(sequence_output)\n",
    "#         h12 = hidden_states[-1][:,0].view(1,bs,768)\n",
    "#         h11 = hidden_states[-2][:,0].view(1,bs,768)\n",
    "#         concat_hidden = torch.cat((h12,h11),2)   # 1 bs 768\n",
    "#         x, _ = self.bilstm1(concat_hidden)# in 1536  out 512\n",
    "#         x = x.permute(1, 0, 2)\n",
    "#         # x形状是(batch_size, seq_len, 2 * num_hiddens)\n",
    "\n",
    "#         # Attention过程\n",
    "#         u = torch.tanh(torch.matmul(x, self.w_omega))\n",
    "#        # u形状是(batch_size, seq_len, 2 * num_hiddens)\n",
    "#         att = torch.matmul(u, self.u_omega)\n",
    "#        # att形状是(batch_size, seq_len, 1)\n",
    "#         att_score = torch.functional.F.softmax(att, dim=1)\n",
    "#        # att_score形状仍为(batch_size, seq_len, 1)\n",
    "#         scored_x = x * att_score\n",
    "#        # scored_x形状是(batch_size, seq_len, 2 * num_hiddens)\n",
    "#         # Attention过程结束\n",
    "        \n",
    "#         feat = torch.sum(scored_x, dim=1) #加权求和\n",
    "#        # feat形状是(batch_size, 2 * num_hiddens)\n",
    "#         outs = self.decoder(feat)\n",
    "#         return outs\n",
    "#=================================================================        \n",
    "        \n",
    "#=========================V_1=========================================  \n",
    "        bs = len(sequence_output)\n",
    "        h12 = hidden_states[-1][:,0].view(1,bs,768)\n",
    "        h11 = hidden_states[-2][:,0].view(1,bs,768)\n",
    "        concat_hidden = torch.cat((h12,h11),2)\n",
    "        x=self.l5(concat_hidden.view(bs,1536))\n",
    "        x=self.a1(x)\n",
    "        x=self.l3(x)\n",
    "        output=self.l6(x)\n",
    "        return output\n",
    "#=========================V_2=========================================  \n",
    "#         bs = len(sequence_output)\n",
    "#         h12 = hidden_states[-1][:,0].view(1,bs,768)\n",
    "#         h11 = hidden_states[-2][:,0].view(1,bs,768)\n",
    "#         concat_hidden = torch.cat((h12,h11),2)\n",
    "#         x=self.l5(concat_hidden.view(bs,1536))\n",
    "#         x=self.a1(x)\n",
    "#         x=self.l51(x)\n",
    "#         x=self.a1(x)\n",
    "#         x=torch.nn.Dropout(0.1)(x)\n",
    "#         output=self.l6(x)\n",
    "#         return output\n",
    "# if __name__==\"__main__\":\n",
    "#     a=tokenizer(\"328 538 382 809 623 434 355 382 382 363 145\",return_tensors='pt')\n",
    "#     net=BERTClass()\n",
    "#     logit=net(a['input_ids'],a['token_type_ids'],a['attention_mask'])\n",
    "#     print(logit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=torch.device('cpu')):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    acc_sum, n = torch.tensor([0], dtype=torch.float32,device=device), 0\n",
    "    y_pred_, y_true_ = [], []\n",
    "    for data in data_iter:\n",
    "        # If device is the GPU, copy the data to the GPU.\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "        net.eval()\n",
    "        y_hat_ = net(ids, mask, token_type_ids)\n",
    "        with torch.no_grad():\n",
    "            y_pred_+=y_hat_.sigmoid().detach().cpu().numpy().tolist()\n",
    "            y_true_+=targets.cpu().numpy().tolist()\n",
    "    val_auc = metrics.roc_auc_score(y_true_, y_pred_, multi_class='ovo')\n",
    "    log_loss=1-((metrics.log_loss(y_true_, y_pred_))/(17*len(y_pred_)))\n",
    "    return val_auc ,log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def train(epoch,train_iter, test_iter, criterion, num_epochs, optimizer, device):\n",
    "    print('training on', device)\n",
    "    print(len(train_iter))\n",
    "    net.to(device)\n",
    "    best_auc = 0\n",
    "    best_loss=0\n",
    "   # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # 设置学习率下降策略\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=2e-06)  # 余弦退火\n",
    "    for epoch in range(num_epochs):\n",
    "        print('当前学习率：{}'.format(optimizer.param_groups[-1]['lr']))\n",
    "        print(\"=\"*100)\n",
    "        print(\"Epoch-->{}/{}\".format(epoch+1,num_epochs))\n",
    "        print(\"=\"*100)\n",
    "\n",
    "        train_l_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        train_acc_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        n, start = 0, time.time()\n",
    "        y_pred, y_true = [], []\n",
    "        \n",
    "        for data in tqdm(train_iter):\n",
    "            net.train()\n",
    "            optimizer.zero_grad()\n",
    "            ids = data['ids'].to(device, dtype=torch.long)\n",
    "            mask = data['mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            y_hat = net(ids, mask, token_type_ids)\n",
    "            #model=nn.DataParallel(model,device_ids=[0,1,2]) # multi-GPU\n",
    "            loss = criterion(y_hat, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        val_auc ,log_loss = evaluate_accuracy(test_iter, net, device)\n",
    "        print('epoch %d,  valid_auc %.9f,  valid_log %.9f, time %.1f sec' % (epoch + 1, val_auc,log_loss,time.time() - start))\n",
    "        if log_loss > best_loss:\n",
    "            print('正在保存当前最佳模型')\n",
    "            best_loss = log_loss\n",
    "            torch.save(net.state_dict(), 'model3/best.pth')\n",
    "        scheduler.step()  # 更新学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed:2021\n"
     ]
    }
   ],
   "source": [
    "seed_torch(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-77094d456688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# 超参数设置\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 选择损失函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "net = BERTClass()\n",
    "net.to(device)\n",
    "# 超参数设置\n",
    "lr, num_epochs = 1e-5, 60\n",
    "criterion = torch.nn.BCEWithLogitsLoss()  # 选择损失函数\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)  # 选择优化器\n",
    "# Creating the dataset and dataloader for the neural network\n",
    "MAX_LEN = 256\n",
    "train_size = 0.8\n",
    "train_dataset = train_df.sample(frac=train_size,random_state=7)\n",
    "valid_dataset = train_df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "# print(\"FULL  Dataset: {}\".format(train_df.shape))\n",
    "# print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "# print(\"VALID Dataset: {}\".format(valid_dataset.shape))\n",
    "# print(\"TEST  Dataset: {}\".format(test_df.shape))\n",
    "\n",
    "train_set = CustomDataset(train_dataset, tokenizer, 128)\n",
    "valid_set = CustomDataset(valid_dataset, tokenizer, 128)\n",
    "test_set = CustomDataset(test_df, tokenizer, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 16\n",
    "TEST_BATCH_SIZE = 16\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True}\n",
    "\n",
    "valid_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True}\n",
    "\n",
    "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
    "                'shuffle': False}\n",
    "\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "valid_loader = DataLoader(valid_set, **valid_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6c7b0df69e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#0.999954353   0.991\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "train(net,train_loader, valid_loader, criterion, num_epochs, optimizer, device)\n",
    "#0.999954353   0.991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label']=''\n",
    "test_set = CustomDataset(test_df, tokenizer, 128)\n",
    "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
    "                'shuffle': False}\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the best model\n",
      "begin predict.........\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29257a5b82604bb7a08b1c3c1f103f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=188.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def model_predict(net, test_iter):\n",
    "    # 预测模型\n",
    "    preds_list = []\n",
    "    print('loading the best model')\n",
    "    net.load_state_dict(torch.load('model3/best.pth'))\n",
    "    net = net.to(device)\n",
    "    print('begin predict.........')\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_iter):\n",
    "            ids = data['ids'].to(device, dtype=torch.long)\n",
    "            mask = data['mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            batch_preds = net(ids, mask, token_type_ids).sigmoid().detach().cpu().numpy()\n",
    "            for preds in batch_preds:\n",
    "                preds_list.append(preds) \n",
    "    for q,i in enumerate(preds_list):\n",
    "        i=[str(x) for x in i]\n",
    "        preds_list[q]=' '.join(i)\n",
    "    return preds_list\n",
    "preds_list = model_predict(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df:(3000, 2)\n",
      "0|\n"
     ]
    }
   ],
   "source": [
    "test_df=pd.read_csv('dataset/track1_round1_testA_20210222.csv',header=None) \n",
    "test_df.columns=['report_ID','description']\n",
    "submit=test_df.copy()\n",
    "print(\"test_df:{}\".format(test_df.shape))\n",
    "new_des=[i.strip('|').strip() for i in test_df['description'].values]\n",
    "test_df['description']=new_des\n",
    "sub_id=test_df['report_ID'].values\n",
    "#\n",
    "print(sub_id[0])\n",
    "save_dir='submits/'\n",
    "if not os.path.exists(save_dir): os.makedirs(save_dir)\n",
    "str_w=''\n",
    "current_time=time.localtime(time.time())\n",
    "with open(save_dir+'submit{}_{}_{}.csv'.format(current_time.tm_year,current_time.tm_hour,current_time.tm_min),'w') as f:\n",
    "    for i in range(len(sub_id)):\n",
    "        str_w+=sub_id[i]+','+'|'+preds_list[i]+'\\n'\n",
    "    str_w=str_w.strip('\\n')\n",
    "    f.write(str_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,criterion, optimizer, lr_scheduler=None):\n",
    "    total_iters=len(trainloader)\n",
    "    print('total_iters:{}'.format(total_iters))\n",
    "    since = time.time()\n",
    "    best_loss = 1e7\n",
    "    best_epoch = 0\n",
    "    #\n",
    "    iters = len(trainloader)\n",
    "    for epoch in range(1,max_epoch+1):\n",
    "        model.train(True)\n",
    "        begin_time=time.time()\n",
    "        print('learning rate:{}'.format(optimizer.param_groups[-1]['lr']))\n",
    "        print('Fold{}==>Epoch {}/{}'.format(fold+1,epoch, max_epoch))\n",
    "        print('=' * 90)\n",
    "        count=0\n",
    "        train_loss = []\n",
    "        for i, inputs in enumerate(trainloader):\n",
    "            count+=1\n",
    "            ids = inputs['ids'].to(device, dtype = torch.long)\n",
    "            mask = inputs['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = inputs['token_type_ids'].to(device, dtype = torch.long)\n",
    "            labels = inputs['targets'].to(device).float()\n",
    "            #\n",
    "            out_linear= model(ids, mask, token_type_ids)#前向传播（投料）\n",
    "#             print(out_linear.size(),labels.size())\n",
    "            loss = criterion(out_linear, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 更新cosine学习率\n",
    "            if lr_scheduler!=None:\n",
    "                lr_scheduler.step(epoch + count / iters)\n",
    "            if print_interval>0 and (i % print_interval == 0 or out_linear.size()[0] < train_batch_size):\n",
    "                spend_time = time.time() - begin_time\n",
    "                print(\n",
    "                    ' Fold:{} Epoch:{}({}/{}) loss:{:.3f} lr:{:.7f} epoch_Time:{}min:'.format(\n",
    "                        fold+1,epoch, count, total_iters,\n",
    "                        loss.item(), optimizer.param_groups[-1]['lr'],\n",
    "                        spend_time / count * total_iters // 60 - spend_time // 60))\n",
    "            #\n",
    "            train_loss.append(loss.item())\n",
    "        #lr_scheduler.step()\n",
    "        val_auc,val_loss= val_model(model, criterion)\n",
    "        print('valLogLoss: {:.4f} valAuc: {:.4f}'.format(val_loss,val_auc))\n",
    "        model_out_path = model_save_dir+\"/\"+'fold_'+str(fold+1)+'_'+str(epoch) + '.pth'\n",
    "        best_model_out_path = model_save_dir+\"/\"+'fold_'+str(fold+1)+'_best'+'.pth'\n",
    "        #save the best model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_epoch=epoch\n",
    "            torch.save(model.state_dict(), best_model_out_path)\n",
    "            print('='*90)\n",
    "            print(\"|save best epoch: {} best auc: {} best logloss: {}|\".format(best_epoch,val_auc,val_loss))\n",
    "            print('='*90)\n",
    "            print('Fold{} Best logloss: {:.3f} Best epoch:{}'.format(fold+1,best_loss,best_epoch))\n",
    "    time_elapsed = time.time() - since\n",
    "    #print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    return best_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_model(model, criterion):\n",
    "    dset_sizes=len(val_dataset)\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    cont = 0\n",
    "    outPre = []\n",
    "    outLabel = []\n",
    "    pres_list=[]\n",
    "    labels_list=[]\n",
    "    for i, inputs in enumerate(val_loader): \n",
    "            ids = inputs['ids'].to(device, dtype = torch.long)\n",
    "            mask = inputs['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = inputs['token_type_ids'].to(device, dtype = torch.long)\n",
    "            labels = inputs['targets'].to(device).float()\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            pres_list+=outputs.sigmoid().detach().cpu().numpy().tolist()\n",
    "            labels_list+=labels.detach().cpu().numpy().tolist()\n",
    "    val_auc = metrics.roc_auc_score(labels_list, pres_list, multi_class='ovo')\n",
    "    log_loss=1-((metrics.log_loss(labels_list, pres_list))/(17*len(pres_list)))#\n",
    "    return val_auc,log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df:(10000, 2),test_df:(3000, 1)\n",
      "无异常样本: 2622\n",
      "train fold 1\n",
      "total_iters:625\n",
      "learning rate:0.001\n",
      "Fold1==>Epoch 1/10\n",
      "==========================================================================================\n",
      "valLogLoss: 1.0000 valAuc: 0.5497\n",
      "==========================================================================================\n",
      "|save best epoch: 1 best auc: 0.5497449167251046 best logloss: 0.9999778043731692|\n",
      "==========================================================================================\n",
      "Fold1 Best logloss: 1.000 Best epoch:1\n",
      "learning rate:0.00025750000000000013\n",
      "Fold1==>Epoch 2/10\n",
      "==========================================================================================\n",
      "valLogLoss: 1.0000 valAuc: 0.5545\n",
      "learning rate:0.001\n",
      "Fold1==>Epoch 3/10\n",
      "==========================================================================================\n",
      "valLogLoss: 1.0000 valAuc: 0.4615\n",
      "==========================================================================================\n",
      "|save best epoch: 3 best auc: 0.4615045282823918 best logloss: 0.9999776275267709|\n",
      "==========================================================================================\n",
      "Fold1 Best logloss: 1.000 Best epoch:3\n",
      "learning rate:0.0009336825748732972\n",
      "Fold1==>Epoch 4/10\n",
      "==========================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-c33dd449acd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m                             num_workers=4)\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mbest_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mkfold_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local cv:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkfold_best\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfold_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-cb1bfd31ed9e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, lr_scheduler)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;31m# 更新cosine学习率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_df=pd.read_csv('dataset/track1_round1_train_20210222.csv',header=None)\n",
    "test_df=pd.read_csv('dataset/track1_round1_testA_20210222.csv',header=None) \n",
    "#\n",
    "train_df.columns=['report_ID','description','label']\n",
    "test_df.columns=['report_ID','description']\n",
    "train_df.drop(['report_ID'],axis=1,inplace=True)\n",
    "test_df.drop(['report_ID'],axis=1,inplace=True)\n",
    "print(\"train_df:{},test_df:{}\".format(train_df.shape,test_df.shape))\n",
    "#\n",
    "new_des=[i.strip('|').strip() for i in train_df['description'].values]\n",
    "new_label=[i.strip('|').strip() for i in train_df['label'].values]\n",
    "train_df['description']=new_des\n",
    "train_df['label']=new_label\n",
    "new_des=[i.strip('|').strip() for i in test_df['description'].values]\n",
    "test_df['description']=new_des\n",
    "#\n",
    "#总共1w条训练数据里面包含2622条正常样本，这里的正常样本标签就使用[0,0,0,....,0,0]编码\n",
    "print('无异常样本:',train_df[train_df['label']==''].shape[0])#2622\n",
    "\n",
    "# iteration = all_size / batch_size  \n",
    "# epoch = the number of train all_data  \n",
    "model_save_dir ='ckpt/'\n",
    "print_interval=-1\n",
    "train_batch_size=16\n",
    "val_batch_size=32\n",
    "max_epoch=10\n",
    "device = torch.device('cuda')\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "if not os.path.exists(model_save_dir): os.makedirs(model_save_dir)\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2021).split(np.arange(train_df.shape[0]), train_df.label.values)\n",
    "kfold_best=[]\n",
    "tokenizer = BertTokenizer.from_pretrained('pretrain/vocab.txt')\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    #\n",
    "    print('train fold {}'.format(fold+1))\n",
    "    model=BERTClass()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3 ,weight_decay=5e-4)\n",
    "    #lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=2, eta_min=1e-5, last_epoch=-1)\n",
    "\n",
    "    train_dataset = CustomDataset(train_df,tokenizer,trn_idx,64)\n",
    "    trainloader = DataLoader(train_dataset,\n",
    "                            batch_size=train_batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=0)\n",
    "    val_dataset = CustomDataset(train_df,tokenizer,val_idx,64)\n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                            batch_size=val_batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=4)\n",
    "\n",
    "    best_loss=train_model(model,criterion, optimizer,lr_scheduler=lr_scheduler)\n",
    "    kfold_best.append(best_loss)\n",
    "print(\"local cv:\",kfold_best,np.mean(kfold_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(weight_path):\n",
    "    print(weight_path)\n",
    "    model=BERTClass()\n",
    "    model.load_state_dict(torch.load(weight_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "test_dataset = CustomDataset(test_df,tokenizer,val_idx,128)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                    batch_size=val_batch_size,\n",
    "                    shuffle=False,\n",
    "                    num_workers=4)\n",
    "@torch.no_grad()\n",
    "def model_predict(net, test_iter):\n",
    "    # 预测模型\n",
    "    preds_list = []\n",
    "    print('加载最优模型')\n",
    "    net.load_state_dict(torch.load('model/best.pth'))\n",
    "    net = net.to(device)\n",
    "    print('inference测试集')\n",
    "    \n",
    "    for data in tqdm(test_iter):\n",
    "        ids = data['ids'].to(device, dtype=torch.long)\n",
    "        mask = data['mask'].to(device, dtype=torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        batch_preds = net(ids, mask, token_type_ids).sigmoid().detach().cpu().numpy()[0]\n",
    "        for preds in batch_preds:\n",
    "            preds_list.append(preds)           \n",
    "    return preds_list\n",
    "        for i in range(len(model_list)):\n",
    "            model=model_list[i]\n",
    "            outputs=model(text)\n",
    "            outputs=outputs.sigmoid().detach().cpu().numpy()[0]\n",
    "            if i==0:\n",
    "                pres_fold=outputs/len(model_list)\n",
    "            else:\n",
    "                pres_fold+=outputs/len(model_list)\n",
    "        #\n",
    "        pres_fold=[str(p) for p in pres_fold]\n",
    "        pres_fold=' '.join(pres_fold)\n",
    "        pres_all.append(pres_fold)\n",
    "    return pres_all\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    device=torch.device('cuda')\n",
    "    model_list=[]\n",
    "    for i in range(5):\n",
    "        model_list.append(load_model('ckpt/fold_'+str(i+1)+'_best.pth'))\n",
    "    #\n",
    "    test_df=pd.read_csv('dataset/track1_round1_testA_20210222.csv',header=None) \n",
    "    #\n",
    "    test_df.columns=['report_ID','description']\n",
    "    submit=test_df.copy()\n",
    "    print(\"test_df:{}\".format(test_df.shape))\n",
    "    new_des=[i.strip('|').strip() for i in test_df['description'].values]\n",
    "    test_df['description']=new_des\n",
    "    sub_id=test_df['report_ID'].values\n",
    "    #\n",
    "    print(sub_id[0])\n",
    "    save_dir='submits/'\n",
    "    if not os.path.exists(save_dir): os.makedirs(save_dir)\n",
    "    pres_all=predict(new_des)\n",
    "    str_w=''\n",
    "    current_time=time.localtime(time.time())\n",
    "    with open(save_dir+'submit_{}_{}.csv'.format(current_time.tm_hour,current_time.tm_min),'w') as f:\n",
    "        for i in range(len(sub_id)):\n",
    "            str_w+=sub_id[i]+','+'|'+pres_all[i]+'\\n'\n",
    "        str_w=str_w.strip('\\n')\n",
    "        f.write(str_w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
